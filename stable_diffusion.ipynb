{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuFz5uGi-h6G"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet --upgrade diffusers transformers scipy mediapy ipyfilechooser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xpzz_ZmuN9Y"
      },
      "outputs": [],
      "source": [
        "from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler\n",
        "import mediapy as media\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from ipyfilechooser import FileChooser\n",
        "import PIL\n",
        "from PIL import Image\n",
        "plt.ioff();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "outputs": [],
      "source": [
        "def init_model():\n",
        "  global auth_token\n",
        "  global pipe, scheduler\n",
        "\n",
        "  scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True)\n",
        "  # scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "  # scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "\n",
        "  model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "  device = \"cuda\"\n",
        "  remove_safety = True\n",
        "\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16, revision=\"fp16\", use_auth_token=auth_token)\n",
        "  if remove_safety:\n",
        "    pipe.safety_checker = lambda images, clip_input: (images, False)\n",
        "  pipe = pipe.to(device)\n",
        "\n",
        "\n",
        "def generate_image():\n",
        "  global prompt\n",
        "  global pipe\n",
        "  global guidance_scale\n",
        "  global num_inference_steps\n",
        "  global images\n",
        "  global init_image\n",
        "  \n",
        "  try: init_image\n",
        "  except: init_image=None\n",
        "\n",
        "  num_images = 1\n",
        "\n",
        "  prompts = [ prompt ] * num_images\n",
        "  with autocast(\"cuda\"):\n",
        "      images = pipe(prompts, guidance_scale=guidance_scale, init_image=init_image ,num_inference_steps=num_inference_steps)[\"sample\"]  \n",
        "      \n",
        "  media.show_images(images)\n",
        "\n",
        "def reset_init_image():\n",
        "  global init_image\n",
        "  init_image = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnVUdNznuN9a"
      },
      "outputs": [],
      "source": [
        "def simple_ui():\n",
        "    button_clear_output = widgets.Button(description='表示クリア')\n",
        "    button_init_model = widgets.Button(description='モデル初期化')\n",
        "    button_generate_image = widgets.Button(description='生成')\n",
        "    button_reset_init_image = widgets.Button(description='init_image消去')\n",
        "    filechooser = FileChooser('./')\n",
        "    button_load_as_init_image = widgets.Button(description='init_image読込')\n",
        "    \n",
        "    button_input_field = widgets.Button(description='変数反映')\n",
        "\n",
        "    text_auth_token = widgets.Text(value='',description='auth_token')\n",
        "    text_prompt = widgets.Text(value='',description='prompt',layout= widgets.Layout(width='100%'))\n",
        "    float_guidance_scale = widgets.FloatText(value=7.5, description='guidance_scale')\n",
        "    int_num_inference_steps = widgets.IntText(value=50, description='num_inference_steps')\n",
        "\n",
        "    output = widgets.Output()\n",
        "    def wrapped_func_factory(func):\n",
        "        def new_func(ui_element):\n",
        "            with output:\n",
        "                print(f\"exec func {func.__name__}\")\n",
        "                func()\n",
        "                print(f\"complete {func.__name__}\")\n",
        "        return new_func\n",
        "    button_clear_output.on_click(lambda button: output.clear_output(wait=False))\n",
        "    button_init_model.on_click(wrapped_func_factory(init_model))\n",
        "    button_generate_image.on_click(wrapped_func_factory(generate_image))\n",
        "    button_reset_init_image.on_click(wrapped_func_factory(reset_init_image))\n",
        "\n",
        "    def load_as_init_image():\n",
        "        global init_image\n",
        "        path = filechooser.selected\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        w, h = image.size\n",
        "        print(f\"loaded input image of size ({w}, {h}) from {path}\")\n",
        "        w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "        image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "        image = np.array(image).astype(np.float32) / 255.0\n",
        "        image = image[None].transpose(0, 3, 1, 2)\n",
        "        image = torch.from_numpy(image)\n",
        "        init_image = 2.*image - 1.\n",
        "    button_load_as_init_image.on_click(wrapped_func_factory(load_as_init_image))\n",
        "    \n",
        "    def load_input_field():\n",
        "        global auth_token\n",
        "        global prompt\n",
        "        global guidance_scale\n",
        "        global num_inference_steps\n",
        "        auth_token = text_auth_token.value\n",
        "        prompt = text_prompt.value\n",
        "        guidance_scale = float_guidance_scale.value\n",
        "        num_inference_steps = int_num_inference_steps.value\n",
        "    button_input_field.on_click(wrapped_func_factory(load_input_field))\n",
        "\n",
        "    display(\n",
        "        widgets.HBox([button_clear_output, button_init_model, button_generate_image,button_reset_init_image]),\n",
        "        widgets.HBox([filechooser,button_load_as_init_image]),\n",
        "        widgets.Accordion(children=[\n",
        "            widgets.VBox([\n",
        "                widgets.HBox([text_auth_token, float_guidance_scale, int_num_inference_steps ,button_input_field]),\n",
        "                widgets.HBox([text_prompt]),\n",
        "            ])\n",
        "        ],  _titles={0:'各種設定'}, selected_index=None),\n",
        "        output,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIN3vqlzuN9c"
      },
      "outputs": [],
      "source": [
        "simple_ui()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8e61b4300f0ee386dc694cfff950515e4061399049ff0282e8295cd476b41b4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}